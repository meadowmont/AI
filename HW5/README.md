This project explores how key DQN hyperparameters influence an agentâ€™s learning behavior in a car-in-a-grid environment. 
The focus of the assignment is to gain practical insight into two core components of Deep Q-Learning:

Exploration vs. Exploitation (Epsilon): How quickly or slowly the agent shifts from random exploration to using its learned policy.

Planning Horizon (Gamma): How short-sighted or far-sighted the agent becomes when evaluating future rewards.

The Python file tweaked and ran 6 total times to represent different epsilon decay and gamma values.
The pdf contains my writeup of the assignment.
